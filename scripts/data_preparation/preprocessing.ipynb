{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This notebook does some pre-processing of the unstructured data gathered by the scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_path = '../../data/scrape_results_redo'\n",
    "outdir = '../../data/derived_data/analysis_redo'\n",
    "\n",
    "# import the raw video info json\n",
    "raw = pd.read_json(os.path.join(scrape_path, 'video_info.json'),\n",
    "                   orient='index')\n",
    "raw.reset_index(inplace=True)\n",
    "raw.rename(index=str, columns={\"index\": \"video_id\"}, inplace=True)\n",
    "raw.to_csv(os.path.join(outdir, 'video_info.csv'),\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an adjacency list \n",
    "\n",
    "Combine the BFS tree searches into one big ol' adjacency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of out-edges\n",
    "result = {}\n",
    "\n",
    "# populate the dictionary\n",
    "for folder in os.listdir(scrape_path):\n",
    "    if not os.path.isdir(os.path.join(scrape_path, folder)):\n",
    "        continue\n",
    "        \n",
    "    with open(os.path.join(scrape_path, folder, 'search_info.json'), 'r') as f:\n",
    "        search_info = json.load(f)\n",
    "        \n",
    "    for video_id in search_info:\n",
    "        if video_id in result:\n",
    "            result[video_id].union(set(search_info[video_id]['recommendations']))\n",
    "        else:\n",
    "            result[video_id] = set(search_info[video_id]['recommendations'])\n",
    "\n",
    "# save as adjacency list\n",
    "f = open(os.path.join(outdir, 'adjacency_list.txt'), 'w')\n",
    "for video_id in result:\n",
    "    line = \"{} {}\".format(video_id, \" \".join(result[video_id]))\n",
    "    f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make search info dataframe\n",
    "\n",
    "The json search_info format was nice for scraping, not nice for analyzing. Pack it into one csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['video_id', 'recommendations', 'depth', 'search', 'query',\n",
    "           'search_splits', 'search_depth', 'root_video']\n",
    "result = pd.DataFrame(columns=columns)\n",
    "\n",
    "for folder in os.listdir(scrape_path):\n",
    "    if not os.path.isdir(os.path.join(scrape_path, folder)):\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(scrape_path, folder, 'params.json'), 'r') as f:\n",
    "        params = json.load(f)\n",
    "    \n",
    "    filepath = os.path.join(scrape_path, folder, 'search_info.json')\n",
    "    search_df = pd.read_json(filepath, orient='index').reset_index()\n",
    "    search_df.rename(index=str, columns={'index': 'video_id'}, inplace=True)\n",
    "    \n",
    "    search_df['search'] = folder\n",
    "    search_df['query'] = folder.split(\"_\")[0]\n",
    "    search_df['search_splits'] = params['n_splits']\n",
    "    search_df['search_depth'] = params['depth']\n",
    "    search_df['root_video'] = folder.split(\"_\")[1]\n",
    "    \n",
    "    result = result.append(search_df, ignore_index=True)\n",
    "    \n",
    "result.to_csv(os.path.join(outdir, 'search_info.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open adjacency list\n",
    "f = open(os.path.join(outdir, 'adjacency_list.txt'), 'r')\n",
    "\n",
    "in_degrees = {}\n",
    "out_degrees = {}\n",
    "\n",
    "for line in f.read().splitlines():\n",
    "    out_degrees[line.split(\" \")[0]] = len(line.split(\" \")[1:])\n",
    "    for ix, video_id in enumerate(line.split(\" \")):\n",
    "        if ix == 0 or video_id == \"\":\n",
    "            continue\n",
    "        if video_id in in_degrees:\n",
    "            in_degrees[video_id] += 1\n",
    "        else:\n",
    "            in_degrees[video_id] = 1\n",
    "            \n",
    "in_deg = pd.DataFrame.from_dict(in_degrees, orient=\"index\")\n",
    "in_deg = in_deg.rename(index=str, columns={0: 'in_deg'})\n",
    "\n",
    "out_deg = pd.DataFrame.from_dict(out_degrees, orient=\"index\")\n",
    "out_deg = out_deg.rename(index=str, columns={0: 'out_deg'})\n",
    "\n",
    "full = in_deg.join(out_deg, how='left').reset_index()\\\n",
    "             .rename(index=str, columns={'index': 'video_id'})\n",
    "    \n",
    "full.to_csv(os.path.join(outdir, 'vertex_degrees.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pageranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the graph from adjacency list\n",
    "G = nx.read_adjlist(create_using=nx.DiGraph(), \n",
    "                    path=os.path.join(outdir, \"adjacency_list.txt\"))\n",
    "\n",
    "# load pageranks into a dataframe\n",
    "pr = nx.pagerank(G)\n",
    "pr_df = pd.DataFrame.from_dict(pr, orient=\"index\").reset_index()\\\n",
    "                 .rename(index=str, columns={'index': 'video_id', 0: 'pagerank'})\n",
    "    \n",
    "pr_df.to_csv(os.path.join(outdir, 'pageranks.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
