{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('../../data/crawl.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT r.* FROM recommendations r\n",
    "LEFT JOIN searches s\n",
    "  ON r.search_id=s.search_id\n",
    "WHERE s.date = '2019-08-31'\n",
    "    AND video_id NOT NULL\n",
    "'''\n",
    "\n",
    "recs = pd.read_sql_query(sql, con)\n",
    "recs = recs.query(\"search_id == 34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def collapse_multiples(l, factor):\n",
    "    '''\n",
    "    Collapses `factor` duplicates of element in list into a single element.\n",
    "    e.g. if l = [1,1,2,3,3,3,3] then collapse_multiples(l, 2) returns [1,2,3,3]\n",
    "    \n",
    "    INPUT:\n",
    "        l: list\n",
    "        factor: (int) collapse factor\n",
    "    \n",
    "    OUTPUT:\n",
    "        collapsed list\n",
    "    \n",
    "    '''\n",
    "    Counter(l)\n",
    "    res = []\n",
    "    for elem, n in Counter(l).items():\n",
    "        if n % factor == 0:\n",
    "            n /= factor\n",
    "        res.extend([elem] * int(n))\n",
    "    return res\n",
    "    \n",
    "\n",
    "def complete_tree_setup(df):\n",
    "    \"\"\"\n",
    "    `complete_tree`-specific helper. Sets up deep copy of df + dicts of\n",
    "    video depths and recommendations for speedy lookup\n",
    "    \n",
    "    INPUT:\n",
    "        pd.DataFrame of recommendations\n",
    "    \n",
    "    OUTPUT \n",
    "        res: (pd.DataFrame) deep copy of df with vertex_id column\n",
    "        depths: (dict) dict of depths for videos in df\n",
    "        recs: (dict) dict of recommendations for videos in df\n",
    "    \n",
    "    \"\"\"\n",
    "    res = df.copy().filter(['video_id', 'recommendation', 'depth'])\n",
    "    res['vertex_id'] = (res\n",
    "                        .groupby(['depth','video_id'])\n",
    "                        .ngroup())\n",
    "    # video depths and recs as dicts for fast lookup\n",
    "    depths = (df[['video_id', 'depth']]\n",
    "                  .drop_duplicates()\n",
    "                  .set_index('video_id')\n",
    "                  .depth\n",
    "                  .to_dict())\n",
    "    recs = (df[['video_id', 'recommendation']]\n",
    "               .groupby('video_id')\n",
    "               .agg(lambda x: list(x))\n",
    "               .recommendation\n",
    "               .to_dict())\n",
    "    return res, depth, recs\n",
    "\n",
    "def list_difference(l1, l2):\n",
    "    \"\"\"\n",
    "    Returns l1 - l2\n",
    "    e.g. list_difference([1,2,2,3,3,4], [2,2,3]) = [1,3,4]\n",
    "    \n",
    "    \"\"\"\n",
    "    return [i for i in l1 if not i in l2 or l2.remove(i)]\n",
    "\n",
    "def sample_list(l, p):\n",
    "    \"\"\"\n",
    "    Returns elements independently with probability p\n",
    "    \n",
    "    INPUT:\n",
    "        l: list to sample\n",
    "        p: probability of keeping each element\n",
    "    \n",
    "    OUTPUT:\n",
    "        sampled list\n",
    "    \"\"\"\n",
    "    inds = np.random.rand(len(l)) < 1/p\n",
    "    return list(np.array(l)[inds])\n",
    "    \n",
    "\n",
    "def complete_tree(df, search_id, n_splits=4, const_depth=5):\n",
    "    \"\"\"\n",
    "    Function which fills in a truncated tree.\n",
    "    \n",
    "    INPUT:\n",
    "        df: pd.DataFrame with out-edges (columns=['video_id', 'depth', 'recommendation'])\n",
    "        search_id: (int) id of the tree to populate\n",
    "        n_splits: (int) splitting factor\n",
    "        const_depth: (int) depth at which out-edges are sampled w.p. 1/n_splits\n",
    "    \n",
    "    OUTPUT:\n",
    "        (pd.DataFrame) full tree\n",
    "    \n",
    "    \"\"\"\n",
    "    res, vid_depths, vid_recs = complete_tree_setup(df)\n",
    "    # get starting vertex index for new additions\n",
    "    v_id = max(res.vertex_id.values)\n",
    "    prev_recs = []\n",
    "    for depth in df.depth.unique():\n",
    "        parent_ids = list((res\n",
    "                     .query('depth == @depth')\n",
    "                     .video_id\n",
    "                     .unique()))\n",
    "        # get the recommendations that were not followed at the next level\n",
    "        truncd_ids = list_difference(prev_recs, parent_ids)\n",
    "        for video_id in truncd_ids:\n",
    "            v_id += 1\n",
    "            # skip if None or we don't have recommendations \n",
    "            if video_id is None or video_id not in vid_recs:\n",
    "                continue\n",
    "        \n",
    "            recs = vid_recs[video_id]\n",
    "            source_depth = vid_depths[video_id]\n",
    "            if depth >= const_depth:\n",
    "                n_followed.append(len(recs))\n",
    "            \n",
    "            # sample if we  are sampling, but our source recommendations were not sampled\n",
    "            if depth >= const_depth and source_depth < const_depth:\n",
    "                recs = sample_list(recs, p=1/len(recs))\n",
    "            \n",
    "            to_append = pd.DataFrame([[video_id, depth, v_id, rec] for rec in recs],\n",
    "                                    columns=['video_id','depth','vertex_id','recommendation'])\n",
    "            res = res.append(to_append)\n",
    "        \n",
    "        # update previous recs \n",
    "        prev_recs = list(res\n",
    "            .query('depth == @depth')\n",
    "            .recommendation\n",
    "            .values)\n",
    "\n",
    "    res = res.assign(search_id=search_id).sort_values(['depth', 'video_id'])\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
