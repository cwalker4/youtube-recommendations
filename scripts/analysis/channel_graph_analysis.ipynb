{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import features df\n",
    "video_info = pd.read_csv('../../data/derived_data/analysis/video_info.csv')\n",
    "\n",
    "# import channel leanings and merge into features\n",
    "channel_leanings = pd.read_csv('../../data/derived_data/analysis/channel_classification.csv')\n",
    "video_info = video_info.merge(channel_leanings, on=['channel_name', 'channel_id'], how='left')\n",
    "\n",
    "# import channel information\n",
    "channel_info = pd.read_csv('../../data/derived_data/analysis/channel_info.csv')\n",
    "\n",
    "# get top 100 channels, by number of visits\n",
    "n = 200\n",
    "counts = (video_info\n",
    "         .groupby('channel_id')['video_id']\n",
    "         .agg('count')\n",
    "         .reset_index()\n",
    "         .rename(columns={'video_id': 'n'}))\n",
    "\n",
    "top_n = (counts\n",
    "        .sort_values('n', ascending = False)\n",
    "        .head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weighted digraph from multi-edge adjacency list\n",
    "G = nx.DiGraph()\n",
    "edges = []\n",
    "with open(os.path.join('../../data/derived_data/analysis/channel_adjacency.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        line_tuple = line.rstrip().split(',')\n",
    "        parent_node = line_tuple[0]\n",
    "        children_dict = dict(Counter(line_tuple[1:]))\n",
    "        edge_tuple = [[parent_node, child, children_dict[child]] for child in children_dict]\n",
    "        edges += edge_tuple\n",
    "\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# add in channel leanings\n",
    "leaning = dict(zip(channel_leanings.channel_id, channel_leanings.leaning))\n",
    "nx.set_node_attributes(G, name='leaning', values=leaning)\n",
    "\n",
    "# save graph as graphml object\n",
    "nx.write_graphml(G, '../../data/derived_data/analysis/channel_graph.graphml')\n",
    "\n",
    "# save a graphml object for the channels we can classify by leaning\n",
    "G_lean = G.subgraph(channel_leanings.channel_id.values)\n",
    "nx.write_graphml(G_lean, '../../data/derived_data/analysis/channel_subgraph.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Top 100 Channels\n",
    "\n",
    "First plotting the adjacency matrix, normalized so that $A_{ij} = Pr(e(i,j))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the top 100 channels subgraph\n",
    "G_top = G.subgraph(top_n.channel_id.values)\n",
    "A_top = nx.adjacency_matrix(G_top).todense()\n",
    "# normalize the mixing matrix so rows sum to 1\n",
    "A_top = A_top / A_top.sum(axis=1)\n",
    "\n",
    "# plot it\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(A_top)\n",
    "plt.colorbar(shrink=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Centralities\n",
    "\n",
    "Get a bunch of centrality measures for each of the channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get centrality measures from the graph\n",
    "evec = nx.eigenvector_centrality(G)\n",
    "indeg = nx.in_degree_centrality(G)\n",
    "outdeg = nx.out_degree_centrality(G)\n",
    "pr = nx.pagerank(G)\n",
    "\n",
    "# make into individual dfs (doesn't seem to be a way to do this all at once?)\n",
    "evec_df = (pd.DataFrame.from_dict(evec, orient='index')\n",
    "          .rename(columns={0: 'evec'}))\n",
    "indeg_df = (pd.DataFrame.from_dict(indeg, orient='index')\n",
    "           .rename(columns={0: 'indeg'}))\n",
    "outdeg_df = (pd.DataFrame.from_dict(outdeg, orient='index')\n",
    "            .rename(columns={0: 'outdeg'}))\n",
    "pr = (pd.DataFrame.from_dict(pr, orient='index')\n",
    "     .rename(columns={0: 'pr'}))\n",
    "\n",
    "# merge everything together into one df\n",
    "centralities = (reduce(lambda x, y: pd.merge(x, y, how='outer',\n",
    "                                          left_index=True,\n",
    "                                          right_index=True),\n",
    "                     [evec_df, indeg_df, outdeg_df, pr])\n",
    "               .reset_index()\n",
    "               .rename(columns={'index':'channel_id'}))\n",
    "\n",
    "# write to csv\n",
    "centralities.to_csv('../../data/derived_data/analysis/channel_centralities.csv',\n",
    "                    index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
