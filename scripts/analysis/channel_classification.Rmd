---
output:
  html_document:
    df_print: paged
  pdf_document:
    number_sections: no
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      cache = FALSE, 
                      warning = FALSE,
                      message = FALSE,
                      cache.lazy = FALSE,
                      # force output to LaTeX (which forces the
                      # imposition of fig.pos) and proper figure alignment
                      fig.align = 'center',
                      fig.pos = 'H')

library(dplyr)
library(here)
library(tidyr)
library(stringr)
library(forcats)
library(readr)
library(RSQLite)

library(kableExtra)
library(gridExtra)

library(ggplot2)
extrafont::loadfonts(quiet = TRUE)
library(GGally)
library(hrbrthemes)
theme_set(theme_ipsum())
library(atheylab.utils)
knitr::knit_hooks$set(inline = function(x) {
  atheylab.utils::pretty_print_inline(x, decimals = 2)
})
library(texreg)

source(here('scripts/analysis/utils.R'))

con <- RSQLite::dbConnect(SQLite(), here('data/crawl.sqlite'))

```

---
title: "Channel Classification Analysis"
---

In this document we take a closer look at our classification of channels by political leaning. We have two methods of classifying channels:

1. Match channel names against bias ratings of news outlets. We use media bias ratings from three sources and construct a final bias classification via majority vote. 
    + Media Bias Fact Check (www.mediabiasfactcheck.com): a leading classifier of the U.S. media landscape. Classifies outlets as extreme-left, left, center-left, center, center-right, right, or extreme right. We collapse this scale to left, center, and right.
    + AdFontes (www.adfontesmedia.com): assigns media outlets polarity and factuality scores. Polarity is an integer rating where a negative score indicates a left-leaning outlet and a positive score indicates a right-leaning outlet. For our purposes we ignore the continuous scale and use the sign of the rating to classify outlets as left- or right-biased.
    + AllSides (www.allsides.com): a news website that crowdsourced bias classifications of media outlets. Bias ratings are "based on blind surveys of people across the political spectrum, multi-partisan analysis and other in-depth analyses as well as tens of thousands of user ratings." Outlets are classified as left, center-left, center, right-center, or right. As with MBFC we collapse this scale to left, right, or center.
2. Use comments (@Jan has more details on this) as a proxy for audience, and classify channels as left or right based on the left- and right-share of their commenters. 

```{r data_import}

################################################################################
# data import + tidying
################################################################################

# read in the classification
channel_classification <- dbGetQuery(con, "SELECT * FROM channel_leanings WHERE channel_id NOT NULL")

# read in the alternate classification and drop duplicate channel_id/leaning pairs
channel_class_alt_raw <- read_csv(here('data/derived_data/channel_classification_alt.csv')) 
channel_class_alt_raw %>%
  select(channel_id, leaning_alt = leaning) %>%
  distinct(channel_id, leaning_alt) -> channel_classification_alt

# some channels have contradictory leaning classifications; drop those channels entirely
channel_classification_alt %>%
  group_by(channel_id) %>%
  mutate(n = n()) %>%
  filter(n == 1) %>%
  select(-n) %>%
  ungroup() -> channel_classification_alt

# get the number of times a video from each channel was recommended
sql <- "
SELECT channel_id, COUNT(*) AS n
  FROM recommendations r
LEFT JOIN videos v
  ON r.recommendation=v.video_id
  AND r.search_id=v.search_id
WHERE channel_id NOT NULL
GROUP BY channel_id
ORDER BY n DESC
"
channel_counts <- dbGetQuery(con, sql)

# import channel information
channel_info <- dbGetQuery(con, "SELECT * FROM channels")

################################################################################
# merge everything together
################################################################################

# join them together
list(channel_counts, channel_classification, channel_classification_alt) %>%
  purrr::reduce(~left_join(.x, .y, by = 'channel_id')) -> channel_leanings

```

# Summaries

First a summary table: how many R/L/C/missing channels do we have that we match to channels we visited?

```{r summ_tbl}
channel_leanings %>%
  select(channel_id, starts_with("leaning")) %>%
  gather(classification, leaning, -channel_id) %>%
  mutate(leaning = ifelse(is.na(leaning), 'unclassified', leaning)) %>%
         #leaning = factor(leaning, levels = c("R", "C", "L", "unclassified"))) %>%
  count(classification, leaning) %>%
  mutate(classification = ifelse(classification == "leaning", "base", "alt")) %>%
  group_by(classification) %>%
  mutate(share = n / sum(n)) %>%
  pivot_wider(names_from = classification, 
              values_from = c(n, share), 
              values_fill = list(n = 0, share = 0)) -> summ_tbl

summ_tbl %>%
  mutate_at(c("share_base", "share_alt"), scales::percent)
```

```{r summ_viz}
summ_tbl %>%
  select(leaning, starts_with("share")) %>%
  pivot_longer(-leaning, names_to = "classification", values_to = "share") %>%
  ggplot() + 
  geom_col(aes('', share, fill = leaning)) + 
  scale_fill_manual(values = c("purple", "blue", "red", "gray")) +
  facet_wrap(~classification) +
  ggtitle('Channel Classification Share') 
```

What if we take into account the number of videos we have from each? R/L/C/missing weighted by number of videos from each channel.

```{r}
channel_leanings %>%
  select(channel_id, starts_with("leaning"), n) %>%
  pivot_longer(cols = starts_with("leaning"),
               names_to = "classification",
               values_to = "leaning") %>%
  mutate(leaning = ifelse(is.na(leaning), 'unclassified', leaning)) %>%
  group_by(classification, leaning) %>%
  summarise(n = sum(n, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(classification = ifelse(classification == "leaning", "base", "alt")) %>%
  group_by(classification) %>%
  mutate(share = n / sum(n)) %>%
  pivot_wider(names_from = classification, 
              values_from = c(n, share), 
              values_fill = list(n = 0, share = 0)) -> summ_tbl_alt

summ_tbl_alt %>%
  mutate_at(c("share_base", "share_alt"), scales::percent)

```

```{r}
summ_tbl_alt %>%
  select(leaning, starts_with("share")) %>%
  pivot_longer(-leaning, names_to = "classification", values_to = "share")  %>%
  ggplot() + 
  geom_col(aes('', share, fill = leaning)) + 
  scale_fill_manual(values = c("purple", "blue", "red", "gray")) + 
  facet_wrap(~classification) + 
  ggtitle('Channel Classification Share Weighted by Visit Count') 

```

# Channel Classification Comparisons

Do the two classifications line up? Here we are comparing the unmatched classification lists. Clearly there is very little overlap between our two classifications.

```{r}
channel_classification %>%
  full_join(channel_classification_alt, by = 'channel_id') %>%
  count(leaning, leaning_alt) %>%
  tidyr::complete(leaning, leaning_alt, fill = list(n = 0)) %>%
  mutate(p = n / sum(n)) %>%
  ggplot(aes(leaning, leaning_alt)) +
  geom_tile(aes(fill = n)) + 
  geom_text(aes(label = n), colour = "white")

```

What do the channels in each classification look like? Note that the information for the base and alternative classifications were pulled at different dates (unsure which date the alternative was pulled on).

```{r}
channel_info %>%
  left_join(channel_leanings, by = 'channel_id') %>%
  select(n_subscribers, n_videos, n_views, leaning, leaning_alt) %>%
  pivot_longer(cols = leaning:leaning_alt,
               names_to = "classification",
               values_to = "leaning") %>%
  pivot_longer(cols = c(n_subscribers, n_videos, n_views),
               names_to = "stat",
               values_to = "val") %>%
  mutate(leaning = ifelse(is.na(leaning), "unclassified", leaning),
         leaning = factor(leaning, levels = c("L", "C", "R", "unclassified"), ordered = TRUE)) %>%
  ggplot(aes(val, fill = leaning, colour = leaning)) + 
  geom_density(alpha=0.08) +
  scale_fill_manual(values = c("blue", "purple", "red", "black")) +
  scale_color_manual(values = c("blue", "purple", "red", "black")) + 
  scale_x_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  facet_grid(classification ~ stat, scales = 'free')

```

Let's take a look at the averages. 

```{r}
channel_info %>%
  left_join(channel_leanings, by = 'channel_id') %>%
  select(n_subscribers, n_videos, n_views, leaning, leaning_alt) %>%
  pivot_longer(cols = leaning:leaning_alt,
               names_to = "classification",
               values_to = "leaning") %>%
  pivot_longer(cols = c(n_subscribers, n_videos, n_views),
               names_to = "stat",
               values_to = "val") %>%
  mutate(leaning = ifelse(is.na(leaning), "unclassified", leaning),
         leaning = factor(leaning, levels = c("L", "C", "R", "unclassified"), ordered = TRUE)) %>%
  group_by(classification, leaning, stat) %>%
  summarise(val = mean(val, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate_at("val", as.numeric) %>%
  ggplot(aes(leaning, val, fill = leaning)) + 
  geom_col() +
  scale_fill_manual(values = c("blue", "purple", "red", "black")) +
  facet_grid(stat ~ classification, scales = "free") + 
  ylab("Average Value")

```


